module Graph

use int.Int
use list.List
use list.Map
use option.Option
use map.Map
use list.Mem
use list.FoldLeft
use list.Length
use list.NthNoOpt
use map.Const
use bool.Bool
use set.Set
use list.Nth


(* [TODO] Utiliser le module Occ pour compter les occurrences d'un élément dans la Map. *)
(* [TODO] Qu'est ce qu'une Map vide en Why3 *)


type value

type tensor_id = int


(* ------------------------------------------------------------------------------------- *)
(* A concrete map, implemented as a list of pairs (tensor_id, option value) *)
(* ------------------------------------------------------------------------------------- *)
(* This is a simple list-based implementation of a map, not efficient for large maps. *)
type lis_map = list (tensor_id, option value)

(* Get an item from the map (spec)*)
(* We return None if the tensor is not in the map. *)
function fget_logic (m: lis_map) (k: tensor_id) : option value =
  match m with
    | Nil -> None
    | Cons (k', v) xs -> if k = k' then v else fget_logic xs k
    end 

(* Get an item from the map (imp)*)
let rec fget (m: lis_map) (k: tensor_id) : option value =
    ensures { result = fget_logic m k}
    variant { m }
    match m with
    | Nil -> None
    | Cons (k', v) xs -> 
        if k = k' then v 
        else fget xs k
    end

(* Set an item in the map (spec) *)
function fset_logic (m: lis_map) (k: tensor_id) (v: option value) : lis_map =
    match m with
    | Nil -> Cons (k, v) Nil
    | Cons (k', v') xs ->
        if k = k' then Cons (k, v) xs
        else Cons (k', v') (fset_logic xs k v)
    end

(* Set an item in the map (imp) *)
let rec fset (m: lis_map) (k: tensor_id) (v: option value) : lis_map =
    ensures { fget_logic result k = v }  (* The value is correctly set *)
    ensures { forall k', v'. Mem.mem (k', v') m -> 
        (k' <> k -> fget_logic result k' = fget_logic m k') }   (* The other values are not modified *)
    variant { m }
    match m with
    | Nil -> Cons (k, v) Nil
    | Cons (k', v') tl ->
        if k = k' then Cons (k, v) tl
        else Cons (k', v') (fset tl k v)
    end

(* An empty lis_map *)
let empty_lis_map: lis_map = Nil

(* Check that get and set are inverses *)
(* This can't be proved automatically? *)


  let rec lemma get_after_set  (m: lis_map)
    ensures { forall t,v. fget_logic (fset_logic m t v) t = v }
    (*proof*)
    = match m with
      | Nil -> ()
      | Cons _ xs -> get_after_set xs
      end
    (*qed*)
    
    
  
(* ---------------------------------------------------------------------------*)
(* The "combined" map that embodies the correspondance between the concrete 
   and abstract maps. *)
(* ---------------------------------------------------------------------------*)

type my_map = {
    cmap : lis_map;
    ghost value : Map.map int value;
    ghost has_value : Set.set tensor_id;
    } 
    invariant { 
        forall t. 
        not has_value t -> fget_logic cmap t = None /\  
        has_value t ->  fget_logic cmap t = Some (Map.get value t)
    }
    by 
    {
        cmap = Nil;
        value = (fun _ -> any value);
        has_value = Set.empty;
    }


(* An empty map *)
let empty_my_map = {
        cmap = Nil;
        value = (fun _ -> any value);
        has_value = Set.empty;
}

    
(* Set an item in the map *)
let my_map_set (m : my_map) (t: tensor_id) (v: option value) : my_map = 
ensures { fget_logic result.cmap t =  v }  (* The value is correctly set *)
    {
        cmap = fset m.cmap t v;
        value =  
            match v with
            | Some v' -> Map.set m.value t v'
            | None -> m.value
        end;
        (* If the value is set, we add the tensor to the set of tensors with a value *)
        (* If the value is None, we remove the tensor from the set of tensors with a value *)
        has_value = 
            match v with
            | Some _ -> Set.add t m.has_value
            | None -> Set.remove t m.has_value
        end;
    }
    

    
(* Get an item from the map *)
let my_map_get (m : my_map) (t : tensor_id) : option value = 
ensures { fget_logic m.cmap t = result }  (* The value is correctly set *)
        fget m.cmap t

(* Get an item from the map *)
function my_map_get_logic (m : my_map) (t: tensor_id) : option value = 
    fget_logic m.cmap t


(* An operator *)
(* [TODO] The inputs / outputs of an operator are typed. *)
(* [TODO] The operator may have parameters, e.g., a convolution kernel size *)
(* [TODO] The operator may have attributes, e.g., a relu activation function *)
(* [TODO] The operator may have a type, e.g., a convolution, an addition, etc. *)
(* [TODO] The operator may have a set of attributes, e.g., a relu activation function *)

(* The binding proposed by a node must comply with these typing constraints *)
type shape =  list int (* dimensions of the tensor *)

(* An operator is a function that takes a list of input tensors and produces a list of output tensors *)
(* [TXX] The operator is defined by its name, its input shapes, and its output shapes *)
type operator = {
    name: string; (* name of the operator *)
    opi: list shape;  (* input shapes *)
    opo: list shape;  (* output shapes *)
}

(* ------------------------------------------------------------------------- *)    
(* [TXX] An operator has at least one output  *)
(* ------------------------------------------------------------------------- *)  
predicate operator_one_output (op: operator) =
    length op.opo > 0

goal operator_one_output_ok :
    let op : operator = { 
                    name="Add" ; 
                    opi= Cons (Cons 1 Nil) (Cons (Cons 1 Nil) Nil)  ; 
                    opo= (Cons (Cons 1 Nil) Nil)  
    } in 
    operator_one_output op

goal operator_one_output_ko :
    let op : operator = { 
                    name="Add" ; 
                    opi= Cons (Cons 1 Nil) (Cons (Cons 1 Nil) Nil)  ; 
                    opo= Nil  
    } in 
    not operator_one_output op


(* A node is an application of an operator *)
(* [TXX] *)
type node = {
    ope: operator; (* The operator referred to by the node *)
    oi: list tensor_id; (* Input tensors, position-wise *)
    ou: list tensor_id; (* Output tensors, position-wise *)
}
(*
[TODO] I cannot use the invariant because, if so, I cannot use {} to construct elements of type node. 

    invariant { 
        length oi = length ope.opi /\
        length ou = length ope.opo
    }
    by 
    {
        ope= { name = ""; opi = Nil; opo = Nil };
        oi = Nil;
        ou = Nil;
    }
*)

(* A graph is a list of tensors and nodes + a list of input and output tensors *)
(* [TXX] *)
type graph = {
    gi: list tensor_id;        (* graph inputs *)
    go: list tensor_id;        (* graph outputs *)
    gt: list tensor_id;   (* graph tensors *)
    gn: list node;         (* graph nodes *)
}

constant add_op : operator = {
    name = "Add";
    opi = Cons (Cons 1 Nil) (Cons (Cons 1 Nil) Nil); (* Two inputs of shape [1] *)
    opo = Cons (Cons 1 Nil) Nil; (* One output of shape [1] *)
}

constant sub_op : operator = {
    name = "Sub";
    opi = Cons (Cons 1 Nil) (Cons (Cons 1 Nil) Nil); (* Two inputs of shape [1] *)
    opo = Cons (Cons 1 Nil) Nil; (* One output of shape [1] *)
}

(* ------------------------------------------------------------------------- *)    
(* [TXX] In a graph, a node provide all operators inputs and ouputs  *)
(* ------------------------------------------------------------------------- *)  
predicate all_operator_ins_and_outs (g: graph) =
    forall n: node. Mem.mem n g.gn -> 
        length n.oi = length n.ope.opi /\ length n.ou = length n.ope.opo

(* Specification tests *)
goal all_operator_ins_and_outs_ok :
let add_op : operator = {
    name = "Add";
    opi = Cons (Cons 1 Nil) (Cons (Cons 1 Nil) Nil); (* Two inputs of shape [1] *)
    opo = Cons (Cons 1 Nil) Nil; (* One output of shape [1] *)
} in
    let g : graph = {
        gi = Cons 1 (Cons 2 Nil);
        go = Cons 3 (Cons 4 Nil);
        gt = Cons 1 (Cons 2 (Cons 3 (Cons 4 Nil)));
        gn = Cons { ope = add_op; 
                    oi = Cons 1 (Cons 2 Nil); 
                    ou = Cons 4 Nil } Nil;
    } in 
    all_operator_ins_and_outs g

goal all_operator_ins_and_outs_ko :
    let g : graph = {
        gi = Cons 1 (Cons 2 Nil);
        go = Cons 3 (Cons 4 Nil);
        gt = Cons 1 (Cons 2 (Cons 3 (Cons 4 Nil)));
        gn = Cons { 
                ope= add_op;
                oi=Cons 1 (Cons 2 Nil); 
                ou= Nil} Nil; (* <= there is no output *)
    } in 
    not all_operator_ins_and_outs g


(* ------------------------------------------------------------------------- *)    
(* [TXX] In a graph, a node has at least one output tensor*)
(* ------------------------------------------------------------------------- *)  
predicate all_node_with_one_output (g: graph) =
    forall n: node. Mem.mem n g.gn -> n.ou <> Nil

(* Specification tests *)
goal all_node_with_one_output_ok:
    let g : graph = {
        gi = Cons 1 (Cons 2 Nil);
        go = Cons 3 (Cons 4 Nil);
        gt = Cons 1 (Cons 2 (Cons 3 (Cons 4 Nil)));
        gn = Cons { ope=add_op; oi=Cons 1 (Cons 2 Nil); ou=Cons 3 (Cons 4 Nil)}
            (Cons { ope=sub_op; oi=Cons 5 (Cons 6 Nil); ou=Cons 7 (Cons 8 Nil)} Nil);
    } in 
    all_node_with_one_output g

(* Specification tests *)
goal all_node_with_one_output_ko:
    let g : graph = {
        gi = Cons 1 (Cons 2 Nil);
        go = Cons 3 (Cons 4 Nil);
        gt = Cons 1 (Cons 2 (Cons 3 (Cons 4 Nil)));
        gn = Cons { ope=add_op; oi=Cons 1 (Cons 2 Nil); ou= Nil} (* This operator has no output *)
            (Cons { ope=sub_op; oi=Cons 5 (Cons 6 Nil); ou=Cons 7 (Cons 8 Nil)} Nil);
    } in 
    not all_node_with_one_output g


(* ------------------------------------------------------------------------- *)    
(* [TXX] In a graph, a tensor is either an input of the graph or the output of at most one node *)
(* i.e., there is no dangling tensor. *)
(* ------------------------------------------------------------------------- *)  
(* The initial spec was using existential quantification that show to be difficult to prove:
predicate tensor_is_unique_output (g: graph) =
  forall t: tensor_id.
    mem t g.gt ->
    (mem t g.gi \/
      (exists n: node.
        mem n g.gn /\ mem t n.ou /\
          (forall n': node.
             (mem n' g.gn /\ mem t n'.ou) -> n = n')))

I have replaced them with a simple counting.
*) 

(* Returns all elements of the list that satisfy the predicate b *)
let rec filter ( b: node -> bool) (l: list node) : list node =
    (* The result contains only nodes that satisfy predicate b *)
    ensures { forall n. Mem.mem n result <-> (Mem.mem n l /\ b n) }  
    variant {l}
    match l with
    | Nil -> Nil
    | Cons x xs ->
        if b x then Cons x (filter b xs)
        else filter b xs
    end


function filter ( b: node -> bool) (l: list node) : list node =
    match l with
    | Nil -> Nil
    | Cons x xs ->
        if b x then Cons x (filter b xs)
        else filter b xs
    end


function outputs_for (t: tensor_id) (g: graph) : list node =
  filter (fun n -> Mem.mem t n.ou) g.gn

predicate tensor_output_of_node (g: graph) (t: tensor_id) (n: node) =
  Mem.mem n g.gn /\ Mem.mem t n.ou

predicate tensor_output_exactly_one_node (g: graph) (t: tensor_id) =
  Length.length (outputs_for t g) = 1

predicate no_dangling_tensor (g: graph) =
  forall t: tensor_id.
    Mem.mem t g.gt ->
      Mem.mem t g.gi \/ tensor_output_exactly_one_node g t


(* Specification tests *)
goal no_dangling_tensor_ok: 
    let g : graph = {
        gi = Cons 1 (Cons 2 Nil);
        go = Cons 3 (Cons 4 Nil);
        gt = Cons 1 (Cons 2 (Cons 3 (Cons 4 Nil)));
        gn = Cons { ope= add_op; oi=Cons 1 (Cons 2 Nil); ou=Cons 3 Nil}
            (Cons { ope=sub_op; oi=Cons 1 (Cons 2 Nil); ou=Cons 4  Nil} Nil);
    } in 
    no_dangling_tensor g


goal no_dangling_tensor_ko_1: (* Tensor 3 is the output of two nodes *)
    let g : graph = {
        gi = Cons 1 (Cons 2 Nil);
        go = Cons 3 Nil;
        gt = Cons 1 (Cons 2 (Cons 3 (Cons 4 Nil)));
        gn = Cons { ope=add_op; oi=Cons 1 (Cons 2 Nil); ou=Cons 3 Nil}
            (Cons { ope=sub_op; oi=Cons 1 (Cons 2 Nil); ou=Cons 3 Nil} Nil);
    } in 
    not no_dangling_tensor g

goal no_dangling_tensor_ko_2: (* Tensor 4 is dangling *)
    let g : graph = {
        gi = Cons 1 (Cons 2 Nil);
        go = Cons 3 (Cons 4 Nil);
        gt = Cons 1 (Cons 2 (Cons 3 (Cons 4 Nil)));
        gn = Cons { ope=add_op; oi=Cons 1 (Cons 2 Nil); ou=Cons 3  Nil}
            (Cons { ope=sub_op; oi=Cons 1 (Cons 2 Nil); ou=Cons 3  Nil} Nil);
    } in 
    not no_dangling_tensor g


(* ------------------------------------------------------------------------- *)    
(* [TXX] A graph input is the input of at least one node *)
(* (No useless input) *)
(* ------------------------------------------------------------------------- *)    
predicate graph_ins_are_node_ins  (g: graph) =
forall t: tensor_id.
    Mem.mem t g.gi ->
        exists op. Mem.mem op g.gn /\ Mem.mem t op.oi

(* Specification tests *)
goal graph_ins_are_node_ins_test_ok:
    let g : graph = {
        gi = Cons 1 (Cons 2 Nil);
        go = Cons 3 (Cons 4 Nil);
        gt = Cons 1 (Cons 2 (Cons 3 (Cons 4 Nil)));
        gn = Cons { ope=add_op; oi=Cons 1 (Cons 2 Nil); ou=Cons 3 (Cons 4 Nil)} Nil;
    } in 
    graph_ins_are_node_ins g

goal graph_ins_are_node_ins_test_ko:
    let g : graph = {
        gi = Cons 1 (Cons 2 Nil);
        go = Cons 3 (Cons 4 Nil);
        gt = Cons 1 (Cons 2 (Cons 3 (Cons 4 Nil)));
        gn = Cons { ope=add_op; oi=Cons 5 (Cons 2 Nil); ou= Cons 3 Nil } Nil;
    } in 
    not graph_ins_are_node_ins g

(* ------------------------------------------------------------------------- *)    
(* [TXX] A graph output is the output of one node *)
(* ------------------------------------------------------------------------- *)    
predicate graph_outs_are_node_outs (g: graph) =
    forall t: tensor_id. Mem.mem t g.go ->
        exists n. Mem.mem n g.gn /\ Mem.mem t n.ou

(* Specification tests *)
goal graph_outs_are_node_outs_test_ok:
    let g : graph = {
        gi = Cons 1 (Cons 2 Nil);
        go = Cons 3 (Cons 4 Nil);
        gt = Cons 1 (Cons 2 (Cons 3 (Cons 4 Nil)));
        gn = Cons { ope=add_op; oi=Cons 1 (Cons 2 Nil); ou=Cons 3 (Cons 4 Nil)} Nil;
    } in 
    graph_outs_are_node_outs g

goal graph_outs_are_node_outs_test_ko:
    let g : graph = {
        gi = Cons 1 (Cons 2 Nil);
        go = Cons 3 (Cons 4 Nil);
        gt = Cons 1 (Cons 2 (Cons 3 (Cons 4 Nil)));
        gn = Cons { ope=add_op; oi=Cons 1 (Cons 2 Nil); ou= Cons 3 Nil } Nil;
    } in 
    not graph_outs_are_node_outs g


(* ------------------------------------------------------------------------- *)    
(* [TXX] Graph inputs and ouputs belong to the set of tensors  *)
(* ------------------------------------------------------------------------- *)    
predicate graph_ins_outs_are_tensors (g: graph) =
    forall t: tensor_id. (Mem.mem t g.gi \/ Mem.mem t g.go) -> Mem.mem t g.gt

(* Specification tests *)
goal graph_ins_outs_are_tensors_test_ok:
    let g : graph = {
        gi = Cons 1 (Cons 2 Nil);
        go = Cons 3 (Cons 4 Nil);
        gt = Cons 1 (Cons 2 (Cons 3 (Cons 4 Nil)));
        gn = Cons { ope=add_op; oi=Cons 1 (Cons 2 Nil); ou=Cons 3 (Cons 4 Nil)} Nil;
    } in 
    graph_ins_outs_are_tensors g

goal graph_ins_outs_are_tensors_test_ko:
    let g : graph = {
        gi = Cons 1 (Cons 2 Nil);
        go = Cons 3 (Cons 4 Nil); (* <= Output 4 is not in the tensor set *)
        gt = Cons 1 (Cons 2 (Cons 3 (Cons 5 Nil)));
        gn = Cons { ope=add_op; oi=Cons 1 (Cons 2 Nil); ou= Cons 3 Nil } Nil;
    } in 
    not graph_ins_outs_are_tensors g


(* ------------------------------------------------------------------------- *)    
(* [TXX] A tensor is either a graph input or a node output  *)
(* ------------------------------------------------------------------------- *)    
predicate no_free_tensor (g: graph) =
    forall t: tensor_id. Mem.mem t g.gt ->
            Mem.mem t g.gi \/ 
            exists n. Mem.mem n g.gn \/ Mem.mem t n.ou





type graph_state = my_map


(* ------------------------------------------------------------------------- *)    
(* True if a tensor t is initialized in state s. *)
(* ------------------------------------------------------------------------- *)    
predicate tensor_is_initialized (s: graph_state) (t: tensor_id) =
    match fget_logic s.cmap t with
    | Some _ -> true
    | None -> false
end

(* ------------------------------------------------------------------------- *)    
(* Returns true if a tensor t is initialized in state s. *)
(* ------------------------------------------------------------------------- *)    
let is_initialized (s: graph_state) (t: tensor_id) : bool 
ensures { result = tensor_is_initialized s t }
=
    match fget s.cmap t with
    | Some _ -> true
    | None -> false
    end

(* ------------------------------------------------------------------------- *)    
(* Returns true if all tensors in the list are initialized in state s. *)
(* ------------------------------------------------------------------------- *)    
let rec are_initialized (s: graph_state) (l: list tensor_id) : bool = 
ensures { result = forall t. Mem.mem t l -> tensor_is_initialized s t }
variant {l} 
match l with 
| Nil -> true
| Cons x xs -> (is_initialized s x) && (are_initialized s xs)
end



(* ------------------------------------------------------------------------- *)    
(* True if node op is executable in state s *)
(* ------------------------------------------------------------------------- *)    
predicate node_is_ready (s: graph_state) (op: node) =
    (* A node is ready if all its inputs tensors are initialized *)
    forall t: tensor_id. 
        Mem.mem t op.oi -> tensor_is_initialized s t

let node_ready (s: graph_state) (op: node) : bool
ensures { result = true <-> node_is_ready s op } 
=
    are_initialized s op.oi



(* =========================================================================== *)
(* Utilities *)
(* =========================================================================== *)

(* Create t list of n elements with the same value x *)
let rec make_list (x: 'a) (n: int) : list 'a
requires { n >= 0 }
ensures{ length result = n}  
ensures{ forall v. Mem.mem v result -> v = x }  
variant { n }
= 
    if n = 0 
    then 
        Nil
    else 
        Cons x (make_list x (n - 1))


(* Fold implementation with two parameters *)   
(* [TODO] See fold_product in List*)
let rec fold_left2  (f: 'acc -> 'a -> 'b -> 'acc) 
                    (acc: 'acc) 
                    (l1: list 'a) 
                    (l2: list 'b) : 'acc 
    requires { length l1 = length l2 }
    variant { l1 }
    = match l1, l2 with
    | Nil, Nil -> acc
    | Cons x xs, Cons y ys -> fold_left2 f (f acc x y) xs ys
    | _, _ -> absurd
    end

(* Apply a function on all elements of a list  *)
let rec apply (f: 'a -> 'b) (l: list 'a) : list 'b
ensures { length result = length l }
variant { l }
= match l with
    | Nil -> Nil
    | Cons x xs -> Cons (f x) (apply f xs)
end


(* =========================================================================== *)
(* Operators *)
(* =========================================================================== *)

(* Computes the outputs of a node  *)
(* Currently, this is a dummy implementation that returns a list of identical values *)
function eval_operator_log (op: operator) (inputs: list (option value)) : list (option value) 

(* Function modeling the behavior of an operator *)
(* [TODO] Replace with actual operators *)
let eval_operator (op: operator) (inputs: list (option value)) : list (option value) 
    (* The node provides as any iputs as needed by the operator *)
    requires { length inputs = length op.opi } 
    (* All inputs are initialized before execution *)
    requires { forall i. Mem.mem i inputs -> i <> None } 
    (* All outputs are initialized after execution*) 
    ensures { forall i. Mem.mem i result -> i <> None }  
    (* There is one value per output tensor *)
    ensures { length result = length op.opo }
=
    (* This is a dummy implementation that returns the appropriate number of values *)
    make_list (Some (any value)) (length op.opo)


(* =========================================================================== *)
(* Graph execution *)
(* =========================================================================== *)

(* The two functions could be merged into one, but weep it as it to make it more general... *)
function project (l : lis_map) : list tensor_id =
    match l with
    | Nil -> Nil
    | Cons (t, _) xs -> Cons t (project xs)
    end


predicate t_appears_at_most_once (t: tensor_id) (l: lis_map) =
  forall i j v1 v2.
    Nth.nth i l = Some (t, v1) ->
    Nth.nth j l = Some (t, v2) ->
    i = j


use list.NumOcc
(* This lemma states that if a tensor appears once in the list, then it appears at most once *)
(* [TODO] This lemma is not proved automatically... *)

let rec lemma equivalence_index_counting (l: lis_map) (t: tensor_id)
  ensures { t_appears_at_most_once t l -> NumOcc.num_occ t (project l)  <= 1 }
= match l with
  | Nil -> ()
  | Cons x xs ->
    match x with
    | (t', _) ->
      if t = t' then
        assert { NumOcc.num_occ t (project xs)  = 0 }
      else
        equivalence_index_counting xs t
    end
  end


(*
lev rec lemma xxxx (l: list (tensor_id, value) (t : tensor_id) 
ensures { t_appears_once t l }
*)

let rec assign_list (s: graph_state) (l: lis_map) : graph_state
    (* A tensor shall only appear once in the state *)

    (* A tensor shall only appear once in an assignment *)         
    requires { forall t: tensor_id. t_appears_at_most_once t l }  

    (* The assignment is correct  *)        
    ensures { forall t, v . Mem.mem (t, v) l -> 
        my_map_get_logic result t =  v } 
    variant { l }
=
    match l with
    | Nil -> s  (* Nothing to assign, the state does not change *)
    | Cons (t, v) xs ->
        (* Assign the value and continue with the rest of the assignment list *)
        let s' = my_map_set s t v in
            (* Tensor t is correctly assigned *)
            assert {  my_map_get_logic s' t =  v } ;   
            assume { NumOcc.num_occ t (project xs) = 0  } ;   
            assume { forall t'. t_appears_at_most_once t' xs } ;
            let s'' = assign_list s' xs in 
                assume { forall t'', v'' . Mem.mem (t'', v'') xs -> my_map_get_logic s' t'' =  v'' } ;
                s''  
    end


let rec zip (l1: list tensor_id)(l2: list (option value)) : list (tensor_id, option value)
    requires { length l1 = length l2 }  (* The two lists must have the same length *)
    ensures { length result = length l1 }  (* The result has the same length as the input lists *)
    variant { l1, l2 }
=
    match l1, l2 with
    | Nil, Nil -> Nil  (* Both lists are empty *)
    | Cons t ts, Cons v vs -> Cons (t, v) (zip ts vs)  (* Pair the first elements and continue with the rest *)
    | _, _ -> absurd  (* The lists must have the same length *)
    end


(* --------------------------------------------------------------------------- *)    
(* Execute one node                                                            *)
(* --------------------------------------------------------------------------- *)    
let exec_node (s: graph_state) (n: node) : graph_state
    (* [T05a] The node is ready to be executed *)
    requires { node_is_ready s n }               
    (* [T05a] The number of inputs matches the number of operator's inputs *)   
    requires { length n.oi = length n.ope.opi }  
    (* [T03b] The number of outputs must match the number of operator's outputs *)
    requires { length n.ou = length n.ope.opo }  
    (* After execution, all output tensors are set *)
    ensures  { forall t: tensor_id. Mem.mem t n.ou -> tensor_is_initialized result t } 
=
    (* the values of tensors that are inputs to a node *)
    let inputs = apply (fun t -> my_map_get s t) n.oi in
        assert { forall v.  Mem.mem v inputs -> v <> None  };
    (* the values of all outputs after evaluation *)
    let outputs = eval_operator n.ope inputs in
        assert { forall v.  Mem.mem v outputs -> v <> None  };
        (* the updated state *)
        assign_list s (zip n.ou outputs) 

(* --------------------------------------------------------------------------- *)    
(*  Execute all nodes. 
    Returns the graph state after executing all nodes in the graph 
    The next node to be executed is chosen non deterministically among the 
    executable nodes *)
(* --------------------------------------------------------------------------- *)    

let rec exec_nodes (s: graph_state) (ns: list node) : graph_state = 
    (* All nodes in the list are ready to be executed *)    
    requires { forall n. Mem.mem n ns -> node_is_ready s n }  
    (* All outputs of the nodes are initialized *)
    ensures { forall n : node. Mem.mem n ns -> 
                forall t: tensor_id. Mem.mem t n.ou -> 
                    tensor_is_initialized result t } 
    variant { ns }
    match ns with
    | Nil -> s
    | Cons n ns ->
        let s' = exec_node s n in
            exec_nodes s' ns 
    end


let rec exec_nodes_until_completion (s: graph_state) (ns: list node) : graph_state = 
    (* All outputs of the nodes are initialized *)
    ensures { forall n: node. Mem.mem n ns -> 
                forall t: tensor_id. Mem.mem t n.ou -> 
                    tensor_is_initialized result t } 
    variant {ns}
    let en = filter (fun n -> node_ready s n) ns 
    in 
        let dn = filter (fun n -> not node_ready s n) ns 
        in 
            match en with
            | Nil -> 
                (* No node is ready, return the current state *)
                s  
            | Cons n _ -> 
                (* Execute the node and continue with the remaining nodes *)
                let s' = exec_node s n in
                    exec_nodes_until_completion s' dn  
            end

let ghost exec_graph (s: graph_state) (g: graph) : graph_state 
    (* [T05a] The graph can only be executed if its inputs are initialized *) 
    requires { forall t. Mem.mem t g.gi -> tensor_is_initialized s t }  
     (* [TXX] After execution, all output tensors are initialized *)
    ensures { forall t. Mem.mem t g.go -> tensor_is_initialized result t  }  
    = 
        exec_nodes_until_completion s g.gn 



end
